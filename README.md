# Graph RAG Techniques
**AUTH Diploma Thesis Project**

A comprehensive research project implementing and evaluating various Graph Retrieval-Augmented Generation (RAG) techniques for biomedical question answering. This repository explores multiple approaches to enhance document retrieval using knowledge graphs, neural network models, and advanced graph algorithms.

## Project Scope

This repository implements and compares multiple graph-based retrieval techniques for biomedical question answering:

### **Core Techniques Implemented:**
1. **Traditional Graph RAG**: Basic semantic search with knowledge graph structure
2. **Neural Graph Projection Models**: 
   - Dual Projection Models with contrastive learning
   - Graph Attention Network (GAT) based projection
   - Models with attentive pooling and domain classification
3. **Graph Neural Networks (GNNs)**:
   - Graph autoencoders for node embeddings
   - Heterogeneous GNN models
   - GAT-based query projection
4. **Advanced Retrieval Methods**:
   - Personalized PageRank retrieval
   - Multi-hop neighborhood expansion
   - MeSH subgraph-based retrieval
   - Graph embedding similarity search

### **Key Features:**
- **Multi-modal Knowledge Graph**: Integrates BioASQ questions, PubMed articles, and MeSH terms
- **Comprehensive Evaluation**: Non-LLM and LLM-based evaluation metrics
- **Neo4j Integration**: Full graph database support with advanced querying
- **Scalable Architecture**: Supports both CPU and GPU training/inference
- **Extensible Design**: Modular architecture for easy addition of new techniques

## ğŸ“ Folder Structure

```
graph_rag_techniques/
â”œâ”€â”€ data/                           # Data storage directory (created dynamically)
â”‚   â”œâ”€â”€ raw/                       # Raw datasets and fetched data
â”‚   â”œâ”€â”€ intermediate/              # Processed intermediate data
â”‚   â”œâ”€â”€ external/                  # External data sources
â”‚   â”œâ”€â”€ results/                   # Evaluation results and metrics
â”‚   â”œâ”€â”€ models/                    # Trained model checkpoints
â”‚   â””â”€â”€ output/                    # Generated outputs and visualizations
â”‚
â”œâ”€â”€ images/                        # Architecture diagrams and visualizations
â”‚   â”œâ”€â”€ gat_model_architecture.png
â”‚   â”œâ”€â”€ gnn_architecture_v2.png
â”‚   â”œâ”€â”€ graph_construction_workflow.png
â”‚   â”œâ”€â”€ implementation_overview_workflow.png
â”‚   â””â”€â”€ neo4j_schema_visualization.png
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ configs/                  # Configuration management
â”‚   â”‚   â”œâ”€â”€ config.py            # Environment and path configurations
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collection/         # Data fetching and processing
â”‚   â”‚   â”œâ”€â”€ dataset_constructor.py  # Graph dataset construction
â”‚   â”‚   â”œâ”€â”€ fetcher.py              # PubMed and MeSH data fetchers
â”‚   â”‚   â”œâ”€â”€ reader.py               # BioASQ data reader
â”‚   â”‚   â””â”€â”€ text_splitter.py        # Text chunking utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge_graph/         # Neo4j database management
â”‚   â”‚   â”œâ”€â”€ connection.py        # Neo4j connection handler
â”‚   â”‚   â”œâ”€â”€ crud.py              # Database CRUD operations
â”‚   â”‚   â”œâ”€â”€ loader.py            # Graph data loading utilities
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llms/                    # Language model interfaces
â”‚   â”‚   â”œâ”€â”€ embedding_model.py   # Text embedding models
â”‚   â”‚   â””â”€â”€ llm.py              # Chat model interfaces
â”‚   â”‚
â”‚   â”œâ”€â”€ projection_models/       # Neural projection models
â”‚   â”‚   â”œâ”€â”€ dual_projection_model.py           # Basic dual projection
â”‚   â”‚   â”œâ”€â”€ dual_projection_neo4j_data.py      # Neo4j data processing
â”‚   â”‚   â”œâ”€â”€ projection_gat_model.py            # GAT-based projection
â”‚   â”‚   â”œâ”€â”€ proj_model_with_attentive_pooling.py
â”‚   â”‚   â”œâ”€â”€ proj_model_with_domain_classifier.py
â”‚   â”‚   â”œâ”€â”€ proj_model_with_triplets_.py
â”‚   â”‚   â””â”€â”€ graph_aware/                       # Advanced graph-aware models
â”‚   â”‚       â”œâ”€â”€ gat_projection_model.py
â”‚   â”‚       â”œâ”€â”€ query_gat_loader.py
â”‚   â”‚       â””â”€â”€ train_gat_projection_model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ graph_embeddings/        # GNN models and training
â”‚   â”‚   â”œâ”€â”€ compute_gnn_embeddings.py    # Embedding computation
â”‚   â”‚   â”œâ”€â”€ gnn_data_extraction.py       # Graph data extraction
â”‚   â”‚   â”œâ”€â”€ gnn_data_preparation.py      # PyTorch Geometric data prep
â”‚   â”‚   â”œâ”€â”€ gnn_train.py                 # GNN training pipeline
â”‚   â”‚   â”œâ”€â”€ graph_encoder_model.py       # Graph encoder architectures
â”‚   â”‚   â”œâ”€â”€ hetero_gnn_*                 # Heterogeneous GNN variants
â”‚   â”‚   â”œâ”€â”€ projection_data_processor.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval_techniques/    # Retrieval implementations
â”‚   â”‚   â”œâ”€â”€ base_retriever.py              # Base retriever interface
â”‚   â”‚   â”œâ”€â”€ dual_projection_retriever.py   # Neural projection retrieval
â”‚   â”‚   â”œâ”€â”€ gnn_retriever.py               # GNN-based retrieval
â”‚   â”‚   â”œâ”€â”€ non_ml_retrievers.py           # Traditional graph algorithms
â”‚   â”‚   â””â”€â”€ personalized_pagerank_retriever.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/              # Evaluation frameworks
â”‚   â”‚   â”œâ”€â”€ executor.py          # Evaluation execution pipeline
â”‚   â”‚   â”œâ”€â”€ llm_based_eval.py    # LLM-based evaluation metrics
â”‚   â”‚   â””â”€â”€ non_llm_based_eval.py # Traditional IR metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”‚   â””â”€â”€ utils.py            # General utilities
â”‚   â”‚
â”‚   â””â”€â”€ *.py                     # Main execution scripts
â”‚       â”œâ”€â”€ main.py                     # Primary pipeline runner
â”‚       â”œâ”€â”€ dual_projection_main.py     # Dual projection training
â”‚       â”œâ”€â”€ gat_projection_main.py      # GAT model training
â”‚       â”œâ”€â”€ hetero_graph_encoder_main.py
â”‚       â”œâ”€â”€ graph_autoencoder_training_main.py
â”‚       â”œâ”€â”€ run_dual_projection_evaluation.py
â”‚       â”œâ”€â”€ run_gat_evaluation.py
â”‚       â”œâ”€â”€ evaluate_non_ml_retrievers.py
â”‚       â””â”€â”€ *.ipynb                     # Jupyter notebooks for experiments
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                   # This documentation
```

## ğŸ”§ Prerequisites

### **1. Dataset Requirements**

#### **Primary Dataset:**
- **BioASQ Dataset**: `rag-mini-bioasq` from Hugging Face
  - Source: https://huggingface.co/datasets/enelpol/rag-mini-bioasq
  - Format: Parquet file containing biomedical Q&A pairs
  - Location: Place in `data/raw/bioasq_test.parquet`

#### **External Data Sources:**
- **PubMed Articles**: Automatically fetched via NCBI Entrez API
- **MeSH Term Definitions**: Retrieved from NCBI MeSH database
- **Requirements**: Valid email for NCBI API access

### **2. Database Requirements**

#### **Neo4j Graph Database:**
- **Version**: Neo4j Desktop 1.6.1 or newer
- **Requirements**: 
  - Minimum 4GB RAM allocated to Neo4j
  - Graph Data Science (GDS) plugin installed
  - APOC plugin recommended
- **Database Setup**:
  ```bash
  # Create a new database in Neo4j Desktop
  # Enable GDS and APOC plugins
  # Configure memory settings (minimum 4GB heap)
  ```

#### **Neo4j Graph Schema:**
The system creates the following node types and relationships:
- **Nodes**: `QUESTION`, `CONTEXT`, `ARTICLE`, `MESH_TERM`
- **Relationships**: `HAS_CONTEXT`, `MENTIONS_MESH`, `SIMILAR_TO`

![Neo4j Schema](images/neo4j_schema_visualization.png)

### **3. Environment Configuration**

Create a `.env` file in the project root with the following variables:

```env
# NCBI Entrez API
ENTREZ_EMAIL=your_email@example.com

# Neo4j Database Connection
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password
NEO4J_PUBMED_DATABASE=bioasq
```

### **4. Python Environment**

#### **System Requirements:**
- **Python**: 3.8+ (recommended: 3.9+)
- **CUDA**: Optional but recommended for GPU acceleration
- **Memory**: Minimum 16GB RAM (32GB recommended for large datasets)

#### **Installation:**
```bash
# Clone the repository
git clone <repository_url>
cd graph_rag_techniques

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Prerequisites to Run Models

### **1. Data Preparation Pipeline**

#### **Step 1: Dataset Construction**
```python
# Run the main pipeline to construct graph dataset
python src/main.py
# This will:
# 1. Read BioASQ data
# 2. Fetch PubMed articles
# 3. Retrieve MeSH definitions
# 4. Create graph-ready dataset
```

#### **Step 2: Load Data into Neo4j**
```python
# Load constructed data into Neo4j
# Uncomment the load_graph_data section in main.py
python src/main.py
```

### **2. Model Training Prerequisites**

#### **For Query Projection Models:**
```bash
# Ensure Neo4j is running and populated with data
# Train dual projection model
python src/dual_projection_main.py

# Train GAT projection model
python src/gat_projection_main.py
```

#### **For GNN Models:**
```bash
# Train graph autoencoder for node embeddings
python src/graph_autoencoder_training_main.py

# Train heterogeneous GNN
python src/hetero_graph_encoder_main.py
```

### **3. Evaluation Prerequisites**

#### **Non-ML Retrievers:**
```bash
# Evaluate traditional graph algorithms
python src/evaluate_non_ml_retrievers.py
```

#### **Neural Model Evaluation:**
```bash
# Evaluate dual projection models
python src/run_dual_projection_evaluation.py

# Evaluate GAT models
python src/run_gat_evaluation.py
```

### **4. Hardware Recommendations**

#### **Minimum Requirements:**
- **CPU**: 4+ cores
- **RAM**: 16GB
- **Storage**: 10GB free space
- **GPU**: Optional (CPU training supported)

#### **Recommended for Optimal Performance:**
- **CPU**: 8+ cores (Intel i7/AMD Ryzen 7+)
- **RAM**: 32GB+
- **GPU**: NVIDIA RTX 3070+ or equivalent with 8GB+ VRAM

### **5. Model-Specific Requirements**

#### **GAT Models:**
- Requires subgraph construction (memory intensive)
- Recommended: GPU with 8GB+ VRAM
- Training time: 2-6 hours depending on dataset size

#### **GNN Autoencoders:**
- Requires full graph in memory
- Memory usage scales with graph size
- Training time: 1-3 hours

#### **Dual Projection Models:**
- Lightweight compared to graph models
- Can run efficiently on CPU
- Training time: 30 minutes - 2 hours

## ğŸ“Š Usage Examples

### **Basic Pipeline Execution:**
```python
# Complete pipeline from data to evaluation
python src/main.py  # Data preparation and loading
python src/dual_projection_main.py  # Train projection model
python src/run_dual_projection_evaluation.py  # Evaluate model
```

### **Jupyter Notebook Exploration:**
```bash
# Interactive exploration and experimentation
jupyter notebook src/experiments_notebook.ipynb
jupyter notebook src/gnn_experiments.ipynb
```

### **Visualization:**
```python
# Generate embedding visualizations
python src/run_embeddings_visualization.py
python src/visualize_embeddings_comparison.py
```

## ğŸ“ˆ Evaluation Metrics

The system provides comprehensive evaluation using:

### **Information Retrieval Metrics:**
- **Precision@k, Recall@k, F1@k**
- **Mean Reciprocal Rank (MRR)**
- **Normalized Discounted Cumulative Gain (nDCG@k)**
- **Mean Average Precision (MAP@k)**
- **Success@k, Coverage@k**

### **Graph-Specific Metrics:**
- **Node embedding quality**
- **Graph structure preservation**
- **Subgraph retrieval accuracy**

## ğŸ” Key Components

### **Graph Construction Workflow:**
![Graph Construction](images/graph_construction_workflow.png)

### **Implementation Overview:**
![Implementation Overview](images/implementation_overview_workflow.png)

### **GNN Architecture:**
![GNN Architecture](images/gnn_architecture_v2.png)